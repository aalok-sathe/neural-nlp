{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"/om2/user/ckauf/.result_caching/neural_nlp.models.wrapper.core.ActivationsExtractorHelper._from_sentences_stored\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_layer(model_identifier):\n",
    "    \"\"\"\n",
    "    input: model_identifier of model of which we want to find the last layer\n",
    "    output: last layer identifier\n",
    "    \"\"\"\n",
    "    for ind,filename in enumerate(os.listdir(working_dir)):\n",
    "        model_name = filename.split(\",\")[0]\n",
    "        if \"identifier=\" + model_identifier == model_name:\n",
    "            file = os.path.join(working_dir,filename)\n",
    "            with open(file, 'rb') as f:\n",
    "                result = pickle.load(f)\n",
    "            result = result['data']\n",
    "            layer_list = np.unique(result.layer)\n",
    "            #order double-digit layers at end of list\n",
    "            double_digits = []\n",
    "            if model_identifier in ['distilgpt2','gpt2']:\n",
    "                double_digits = [elm for elm in layer_list if 'encoder.h.' in elm and len(elm.split('.h.')[-1]) > 1]\n",
    "            if model_identifier == 'albert-xxlarge-v2':\n",
    "                double_digits = [elm for elm in layer_list if 'encoder.albert_layer_groups.' in elm and len(elm.split('.albert_layer_groups.')[-1]) > 1]\n",
    "            layers = [e for e in layer_list if e not in double_digits] + double_digits\n",
    "            final_layer = layers[-1]\n",
    "            return final_layer\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_layers(model_identifier):\n",
    "    \"\"\"\n",
    "    input: model_identifier of model of which we want to find the layers\n",
    "    output: np.array of all unique layer identifiers, ordered by position\n",
    "    \"\"\"\n",
    "    for ind,filename in enumerate(os.listdir(working_dir)):\n",
    "        if \"identifier=\" + model_identifier in filename:\n",
    "            file = os.path.join(working_dir,filename)\n",
    "            with open(file, 'rb') as f:\n",
    "                result = pickle.load(f)\n",
    "            result = result['data']\n",
    "            layer_list = np.unique(result.layer)\n",
    "            #order double-digit layers at end of list\n",
    "            double_digits = []\n",
    "            if model_identifier in ['gpt2','distilgpt2']:\n",
    "                double_digits = [elm for elm in layer_list if 'encoder.h.' in elm and len(elm.split('.h.')[-1]) > 1]\n",
    "            if model_identifier == 'albert-xxlarge-v2':\n",
    "                double_digits = [elm for elm in layer_list if 'encoder.albert_layer_groups.' in elm and len(elm.split('.albert_layer_groups.')[-1]) > 1]\n",
    "            layers = [e for e in layer_list if e not in double_digits] + double_digits\n",
    "            return layers\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_passage_identifier(filename):\n",
    "    \"\"\"\n",
    "    get passage identifier to be used as key for the dictionary.\n",
    "    important step: fill the identifier with 0s for single-digit passage numbers\n",
    "    \"\"\"\n",
    "    passage = filename.split(\",\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "    number = passage.split(\"sentences\")[-1]\n",
    "    if len(number) == 1:\n",
    "        passage_identifier = passage[:-1] + number.zfill(2)\n",
    "    else:\n",
    "        passage_identifier = passage\n",
    "    return passage_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(model_identifier, layer_identifier=None):\n",
    "    \"\"\"\n",
    "    input: model identifier\n",
    "    output: populated model dictionary with data of just the selected layer\n",
    "    dictionary structure: passage_identifier --> condition identifier --> data\n",
    "    \"\"\"\n",
    "    model_dictionary = model_identifier + \"_dict\"\n",
    "    model_dictionary = {}\n",
    "    \n",
    "    #look at last layer by default\n",
    "    if layer_identifier == None:\n",
    "        layer_identifier = get_last_layer(model_identifier)\n",
    "    else:\n",
    "        layer_identifier = layer_identifier\n",
    "    print(\"This is the layer I'm looking at: \", layer_identifier)\n",
    "    \n",
    "    for filename in tqdm(os.listdir(working_dir)):\n",
    "        model_name = filename.split(\",\")[0]\n",
    "        if \"identifier=\" + model_identifier == model_name:\n",
    "            passage_identifier = get_passage_identifier(filename)\n",
    "            condition = filename.split(\",\")[-1].split(\"-\")[-2]\n",
    "        \n",
    "            file = os.path.join(working_dir,filename)\n",
    "            with open(file, 'rb') as f:\n",
    "                out = pickle.load(f)\n",
    "            result = out['data']\n",
    "            data = result[{\"neuroid\": [layer == layer_identifier for layer in result[\"layer\"].values]}]\n",
    "        \n",
    "            if not passage_identifier in model_dictionary:\n",
    "                model_dictionary[passage_identifier] = {}\n",
    "            model_dictionary[passage_identifier][condition] = data\n",
    "    \n",
    "    return model_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arrays(dictionary):\n",
    "    #sort dictionary by passage identifier\n",
    "    sorted_dict = dict(sorted(dictionary.items()))\n",
    "    #create empty arrays\n",
    "    #original,scr1,scr3,scr5,scr7,lowpmi,backward,random = ([] for i in range(8))\n",
    "    original,scr1,scr3,scr5,scr7,lowpmi,random = ([] for i in range(7))\n",
    "    #\n",
    "    for key, value in sorted_dict.items(): #key is passage, value is dic from cond to xarray data\n",
    "        original.append(value['Original'].values)\n",
    "        scr1.append(value['Scr1'].values)\n",
    "        scr3.append(value['Scr3'].values)\n",
    "        scr5.append(value['Scr5'].values)\n",
    "        scr7.append(value['Scr7'].values)\n",
    "        lowpmi.append(value['lowPMI'].values)\n",
    "        #backward.append(value['backward'].values)\n",
    "        random.append(value['random'].values)\n",
    "        \n",
    "    #print(np.shape(original))\n",
    "    return original,scr1,scr3,scr5,scr7,lowpmi,random #backward,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_array(liste):\n",
    "    liste_flatten = [item for sublist in liste for item in sublist]\n",
    "    return liste_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def prepare_dataframe(original,scr1,scr3,scr5,scr7,lowpmi,backward,random,flatten=True):\n",
    "def prepare_dataframe(original,scr1,scr3,scr5,scr7,lowpmi,random,flatten=True):\n",
    "    \n",
    "    if flatten:\n",
    "        df = pd.DataFrame(data={'Original':np.asarray(flatten_array(original)).flatten(),\n",
    "                             'Scr1':np.asarray(flatten_array(scr1)).flatten(),\n",
    "                              'Scr3':np.asarray(flatten_array(scr3)).flatten(),\n",
    "                              'Scr5':np.asarray(flatten_array(scr5)).flatten(),\n",
    "                              'Scr7':np.asarray(flatten_array(scr7)).flatten(),\n",
    "                              'lowpmi':np.asarray(flatten_array(lowpmi)).flatten(),\n",
    "                              #'backward':np.asarray(flatten_array(backward)).flatten(),\n",
    "                              'random':np.asarray(flatten_array(random)).flatten()})\n",
    "    if not flatten:\n",
    "        # print(np.shape(np.asarray(flatten_array(random))))\n",
    "        df = {}\n",
    "        df = {'Original':flatten_array(original),\n",
    "                             'Scr1':flatten_array(scr1),\n",
    "                              'Scr3':flatten_array(scr3),\n",
    "                              'Scr5':flatten_array(scr5),\n",
    "                              'Scr7':flatten_array(scr7),\n",
    "                              'lowpmi':flatten_array(lowpmi),\n",
    "                              #'backward':flatten_array(backward),\n",
    "                              'random':flatten_array(random)}\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_df_for_plotting(model_identifier, layer_identifier=None, flatten=True):\n",
    "    model_dict = get_dictionary(model_identifier, layer_identifier)\n",
    "    df = prepare_dataframe(*get_arrays(model_dict), flatten=flatten) #*flattens the tuple\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_dfs_for_all_layers(model_identifier, flatten=True):\n",
    "    \"\"\"\n",
    "    input: model_identifier, whether to flatten (i.e. all sentence reps in one vector or leave 627*hidden size)\n",
    "    output: dictionary: layer --> dataframe (conditions as column names, column values are flattened or unflattened activations)\n",
    "    \"\"\"\n",
    "    layers = get_all_layers(model_identifier)\n",
    "    df_dict = {}\n",
    "    for ind,elm in enumerate(layers):\n",
    "        df_dict[elm] = main_df_for_plotting(model_identifier,layer_identifier=elm,flatten=flatten)\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 1856/7560 [00:00<00:00, 11172.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the layer I'm looking at:  drop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7560/7560 [00:16<00:00, 457.70it/s]  \n",
      " 25%|██▍       | 1858/7560 [00:00<00:00, 17691.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the layer I'm looking at:  encoder.h.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7560/7560 [00:13<00:00, 554.68it/s]  \n",
      " 25%|██▍       | 1858/7560 [00:00<00:00, 18414.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the layer I'm looking at:  encoder.h.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7560/7560 [00:13<00:00, 550.80it/s]  \n",
      " 25%|██▍       | 1859/7560 [00:00<00:00, 17262.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the layer I'm looking at:  encoder.h.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7560/7560 [00:13<00:00, 567.21it/s]  \n",
      " 25%|██▍       | 1858/7560 [00:00<00:00, 18349.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the layer I'm looking at:  encoder.h.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7560/7560 [00:13<00:00, 559.77it/s]  \n",
      " 25%|██▍       | 1858/7560 [00:00<00:00, 18484.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the layer I'm looking at:  encoder.h.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7560/7560 [00:13<00:00, 563.93it/s]  \n",
      " 25%|██▍       | 1858/7560 [00:00<00:00, 18323.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the layer I'm looking at:  encoder.h.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 3071/7560 [00:12<00:29, 150.11it/s]  "
     ]
    }
   ],
   "source": [
    "distilgpt2_correlation_dict = get_activation_dfs_for_all_layers(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distilgpt2_correlation_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distilgpt2_correlation_dict['drop'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_column = distilgpt2_correlation_dict['drop']['Original']\n",
    "conditions = list(distilgpt2_correlation_dict['drop'].columns)\n",
    "\n",
    "for elm in conditions:\n",
    "    correlation = orig_column.corr(distilgpt2_correlation_dict['drop'][elm])\n",
    "    print(elm, correlation)\n",
    "\n",
    "print(\"\\n\")\n",
    "correlations = [orig_column.corr(distilgpt2_correlation_dict['drop'][elm]) for elm in conditions]\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "layers = get_all_layers(\"distilgpt2\")\n",
    "line_colors = sns.color_palette(\"rocket\") + sns.color_palette(\"GnBu_d\")\n",
    "    \n",
    "x = conditions\n",
    "counter = 0\n",
    "for key,value in distilgpt2_correlation_dict.items():\n",
    "    ax.plot(x,correlations, '-o',color=line_colors[counter])\n",
    "    counter += 1\n",
    "\n",
    "    #conditions = list(distilgpt2_score_dict.keys())\n",
    "\n",
    "ax.set_title('Layer model activation correlation with original across conditions')\n",
    "ax.legend(layers)\n",
    "ax.yaxis.set_label_text('Pearson p')\n",
    "plt.xticks(rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations_df_dict(model_identifier): #maybe pass activations dict as input so it doesn't have to recompute\n",
    "    layers = get_all_layers(model_identifier)\n",
    "    activations_dict = get_activation_dfs_for_all_layers(model_identifier)\n",
    "    \n",
    "    conditions = list(activations_dict[layers[0]].columns)\n",
    "    \n",
    "    correlations_df_dict = {}\n",
    "    for layer in layers:\n",
    "        orig_column = activations_dict[layer]['Original']\n",
    "        correlations = [orig_column.corr(activations_dict[layer][elm]) for elm in conditions]\n",
    "        correlations_df_dict[layer] = correlations\n",
    "    \n",
    "    return layers, conditions, correlations_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "layers, conditions, distilgpt2_corr_dict = get_correlations_df_dict(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlations_lineplot(model_identifier, layers, conditions, correlations_dict):\n",
    "    fig, ax = plt.subplots()\n",
    "    line_colors = sns.color_palette(\"rocket\") + sns.color_palette(\"GnBu_d\") + [sns.color_palette(\"PRGn\", 10)[2]] + [sns.color_palette(\"PuOr\", 10)[0]]\n",
    "    \n",
    "    layers = layers\n",
    "    conditions = conditions\n",
    "    \n",
    "    counter = 0\n",
    "    for key,value in correlations_dict.items():\n",
    "        ax.plot(conditions,value, '-o',color=line_colors[counter])\n",
    "        counter += 1\n",
    "\n",
    "    ax.set_title('Layer model activation correlation with model activations for unscrambled sentence across conditions')\n",
    "    ax.legend(layers)\n",
    "    ax.yaxis.set_label_text('Pearson p')\n",
    "    plt.xticks(rotation= 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations_lineplot(\"distilgpt2\", layers, conditions, distilgpt2_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1b_layers, lm1b_conditions, lm1b_corr_dict = get_correlations_df_dict(\"lm_1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations_lineplot(\"lm_1b\", lm1b_layers, lm1b_conditions, lm1b_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_layers, gpt2_conditions, gpt2_corr_dict = get_correlations_df_dict(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlations_lineplot(\"gpt2\", gpt2_layers, gpt2_conditions, gpt2_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#albert_layers, albert_conditions, albert_corr_dict = get_correlations_df_dict('albert-xxlarge-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_correlations_lineplot('albert-xxlarge-v2', albert_layers, albert_conditions, albert_corr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def get_corr_lineplots_loop(model_list):\n",
    "    nsubplots = len(model_list)\n",
    "    nrows = math.ceil(nsubplots/2)\n",
    "    line_colors = sns.color_palette(\"rocket\") + [sns.color_palette(\"PRGn\", 10)[2]] + [sns.color_palette(\"PuOr\", 10)[0]] + sns.color_palette(\"GnBu_d\")\n",
    "    \n",
    "    fig2 = plt.figure(constrained_layout=True, figsize=(15, 5*nrows))\n",
    "    fig2.suptitle('Layer model activation correlation with model activations for unscrambled sentence across conditions', fontsize=22, y=1.05)\n",
    "    spec2 = GridSpec(ncols=2, nrows=nrows, figure=fig2)\n",
    "    f2_ax = []\n",
    "    \n",
    "    model_counter = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(2):\n",
    "            if model_counter + 1 > nsubplots:\n",
    "                break\n",
    "            else:\n",
    "                layers, conditions, correlations_df_dict = get_correlations_df_dict(model_list[model_counter])\n",
    "                f2_ax.append(fig2.add_subplot(spec2[i, j]))\n",
    "                \n",
    "                counter = 0\n",
    "                for key,value in correlations_df_dict.items():\n",
    "                    f2_ax[-1].plot(conditions,value, '-o',color=line_colors[counter])\n",
    "                    counter += 1\n",
    "                f2_ax[-1].set_title('{}'.format(model_list[model_counter]),fontsize=18)\n",
    "                f2_ax[-1].yaxis.set_label_text('Pearson p')\n",
    "                f2_ax[-1].legend(layers)\n",
    "                plt.xticks(rotation= 90)\n",
    "                model_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_corr_lineplots_loop(['glove','lm_1b','distilgpt2', 'gpt2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
