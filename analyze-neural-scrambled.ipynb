{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"/om2/user/ckauf/.result_caching/neural_nlp.models.wrapper.core.ActivationsExtractorHelper._from_sentences_stored\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of what the structure looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.NeuroidAssembly (presentation: 4, neuroid: 5376)>\n",
       "array([[-0.045079,  0.1112  ,  0.058343, ...,  0.358238, -0.26599 ,  0.280199],\n",
       "       [ 0.024145,  0.090933,  0.113967, ..., -0.012236,  0.10889 ,  0.254299],\n",
       "       [-0.112562, -0.150726,  0.18517 , ...,  0.196315,  0.178203,  0.134934],\n",
       "       [ 0.028349, -0.096964,  0.173206, ...,  0.366918, -0.123713,  0.491447]],\n",
       "      dtype=float32)\n",
       "Coordinates:\n",
       "  * presentation       (presentation) MultiIndex\n",
       "  - stimulus_sentence  (presentation) object 'a banana is a long fruit that grows in bunchs with a soft edible inside' ... 'unripe bananas and plantains are staple foods and often cooked like potatoes'\n",
       "  - sentence_num       (presentation) int64 0 1 2 3\n",
       "  * neuroid            (neuroid) MultiIndex\n",
       "  - neuroid_num        (neuroid) int64 0 1 2 3 4 5 6 7 ... 23 24 25 26 27 28 29\n",
       "  - model              (neuroid) object 'distilgpt2' ... 'distilgpt2'\n",
       "  - layer              (neuroid) object 'drop' 'drop' 'drop' ... 'drop' 'drop'\n",
       "  - neuroid_id         (neuroid) object 'distilgpt2.drop.0' ... 'distilgpt2.drop.29'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = os.path.join(working_dir, \"identifier=distilgpt2,stimuli_identifier=Pereira2018-Original-384sentences7.pkl\")\n",
    "with open(file, 'rb') as f:\n",
    "    result = pickle.load(f)\n",
    "\n",
    "data = result['data']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5376)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "# number of sentences in passage * hidden layer activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary\n",
    "### Structure:\n",
    "\n",
    "For all models one separate dictionary structured as follows:\n",
    "* key = sentenceIdentifier _ conditionIdentifier\n",
    "* value = associated unpickled file (assembly like above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "glove_dic = {}\n",
    "lm1b_dic = {}\n",
    "distilgpt2_dic = {}\n",
    "\n",
    "for ind,filename in enumerate(os.listdir(working_dir)):\n",
    "    if ind%500 == 0:\n",
    "        print(ind)\n",
    "        \n",
    "    if \"identifier=glove\" in filename:\n",
    "        passage = filename.split(\",\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "        condition = filename.split(\",\")[-1].split(\"-\")[-2]\n",
    "        #key = passage + \"_\" + condition\n",
    "        file = os.path.join(working_dir,filename)\n",
    "        with open(file, 'rb') as f:\n",
    "            result = pickle.load(f)\n",
    "        #glove_dic[key] = result\n",
    "        if not condition in glove_dic:\n",
    "            glove_dic[condition] = {}\n",
    "        glove_dic[condition][passage] = result\n",
    "        \n",
    "    if \"identifier=lm_1b\" in filename:\n",
    "        passage = filename.split(\",\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "        condition = filename.split(\",\")[-1].split(\"-\")[-2]\n",
    "        #key = passage + \"_\" + condition\n",
    "        file = os.path.join(working_dir,filename)\n",
    "        with open(file, 'rb') as f:\n",
    "            result = pickle.load(f)\n",
    "        #lm1b_dic[key] = result\n",
    "        if not condition in lm1b_dic:\n",
    "            lm1b_dic[condition] = {}\n",
    "        lm1b_dic[condition][passage] = result\n",
    "        \n",
    "    if \"identifier=distilgpt2\" in filename:\n",
    "        passage = filename.split(\",\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "        condition = filename.split(\",\")[-1].split(\"-\")[-2]\n",
    "        #key = passage + \"_\" + condition\n",
    "        #print(key)\n",
    "        file = os.path.join(working_dir,filename)\n",
    "        with open(file, 'rb') as f:\n",
    "            result = pickle.load(f)\n",
    "        #distilgpt2_dic[key] = result\n",
    "        if not condition in distilgpt2_dic:\n",
    "            distilgpt2_dic[condition] = {}\n",
    "        distilgpt2_dic[condition][passage] = result\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Original', 'Scr1', 'Scr3', 'Scr5', 'Scr7', 'backward', 'lowPMI', 'random'])\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "print(glove_dic.keys())\n",
    "print(len(glove_dic['Original']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344\n"
     ]
    }
   ],
   "source": [
    "print(len(glove_dic)) # old, from different iteration // keeping for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick number sanity-check\n",
    "* 8 conditions รก 168 passage encodings >> 8 * 168 = 1344\n",
    "* \n",
    "* 168 * 4 = 672 (Do all passages have 4 sentences?)\n",
    "* 243 + 384 = 627 (No, some must have fewer!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Original': 168, 'Scr1': 168, 'Scr3': 168, 'Scr5': 168, 'Scr7': 168, 'backward': 168, 'lowPMI': 168, 'random': 168}\n"
     ]
    }
   ],
   "source": [
    "cond_dict = {}\n",
    "\n",
    "for ind,filename in enumerate(os.listdir(working_dir)):\n",
    "    if \"identifier=glove\" in filename:\n",
    "        condition = filename.split(\",\")[-1].split(\"-\")[-2]\n",
    "        if not condition in cond_dict:\n",
    "            cond_dict[condition] = 1\n",
    "        else:\n",
    "            cond_dict[condition] += 1\n",
    "print(cond_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________\n",
    "\n",
    "__________________________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* size is passage_len * hidden_layer_size >> Should correlation value come from a matrix norm?\n",
    "* alternatively, we could do independent plots for each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________\n",
    "\n",
    "### Quick change: Better dictionary structure: sentence to condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "glove_dic_senttocond = {}\n",
    "lm1b_dic_senttocond = {}\n",
    "distilgpt2_dic_senttocond = {}\n",
    "\n",
    "for ind,filename in enumerate(os.listdir(working_dir)):\n",
    "    if ind%500 == 0:\n",
    "        print(ind)\n",
    "        \n",
    "    if \"identifier=glove\" in filename:\n",
    "        passage = filename.split(\",\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "        condition = filename.split(\",\")[-1].split(\"-\")[-2]\n",
    "        #key = passage + \"_\" + condition\n",
    "        file = os.path.join(working_dir,filename)\n",
    "        with open(file, 'rb') as f:\n",
    "            result = pickle.load(f)\n",
    "        #glove_dic_senttocond[key] = result\n",
    "        if not condition in glove_dic_senttocond:\n",
    "            glove_dic_senttocond[passage] = {}\n",
    "        glove_dic_senttocond[passage][condition] = result\n",
    "        \n",
    "    if \"identifier=lm_1b\" in filename:\n",
    "        passage = filename.split(\",\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "        condition = filename.split(\",\")[-1].split(\"-\")[-2]\n",
    "        #key = passage + \"_\" + condition\n",
    "        file = os.path.join(working_dir,filename)\n",
    "        with open(file, 'rb') as f:\n",
    "            result = pickle.load(f)\n",
    "        #lm1b_dic_senttocond[key] = result\n",
    "        if not condition in lm1b_dic_senttocond:\n",
    "            lm1b_dic_senttocond[passage] = {}\n",
    "        lm1b_dic_senttocond[passage][condition] = result\n",
    "        \n",
    "    if \"identifier=distilgpt2\" in filename:\n",
    "        passage = filename.split(\",\")[-1].split(\"-\")[-1].split(\".\")[0]\n",
    "        condition = filename.split(\",\")[-1].split(\"-\")[-2]\n",
    "        #key = passage + \"_\" + condition\n",
    "        #print(key)\n",
    "        file = os.path.join(working_dir,filename)\n",
    "        with open(file, 'rb') as f:\n",
    "            result = pickle.load(f)\n",
    "        #distilgpt2_dic_senttocond[key] = result\n",
    "        if not condition in distilgpt2_dic_senttocond:\n",
    "            distilgpt2_dic_senttocond[passage] = {}\n",
    "        distilgpt2_dic_senttocond[passage][condition] = result\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['243sentences1', '243sentences10', '243sentences11', '243sentences12', '243sentences13', '243sentences14', '243sentences15', '243sentences16', '243sentences17', '243sentences18', '243sentences19', '243sentences2', '243sentences20', '243sentences21', '243sentences22', '243sentences23', '243sentences24', '243sentences25', '243sentences26', '243sentences27', '243sentences28', '243sentences29', '243sentences3', '243sentences30', '243sentences31', '243sentences32', '243sentences33', '243sentences34', '243sentences35', '243sentences36', '243sentences37', '243sentences38', '243sentences39', '243sentences4', '243sentences40', '243sentences41', '243sentences42', '243sentences43', '243sentences44', '243sentences45', '243sentences46', '243sentences47', '243sentences48', '243sentences49', '243sentences5', '243sentences50', '243sentences51', '243sentences52', '243sentences53', '243sentences54', '243sentences55', '243sentences56', '243sentences57', '243sentences58', '243sentences59', '243sentences6', '243sentences60', '243sentences61', '243sentences62', '243sentences63', '243sentences64', '243sentences65', '243sentences66', '243sentences67', '243sentences68', '243sentences69', '243sentences7', '243sentences70', '243sentences71', '243sentences72', '243sentences8', '243sentences9', '384sentences1', '384sentences10', '384sentences11', '384sentences12', '384sentences13', '384sentences14', '384sentences15', '384sentences16', '384sentences17', '384sentences18', '384sentences19', '384sentences2', '384sentences20', '384sentences21', '384sentences22', '384sentences23', '384sentences24', '384sentences25', '384sentences26', '384sentences27', '384sentences28', '384sentences29', '384sentences3', '384sentences30', '384sentences31', '384sentences32', '384sentences33', '384sentences34', '384sentences35', '384sentences36', '384sentences37', '384sentences38', '384sentences39', '384sentences4', '384sentences40', '384sentences41', '384sentences42', '384sentences43', '384sentences44', '384sentences45', '384sentences46', '384sentences47', '384sentences48', '384sentences49', '384sentences5', '384sentences50', '384sentences51', '384sentences52', '384sentences53', '384sentences54', '384sentences55', '384sentences56', '384sentences57', '384sentences58', '384sentences59', '384sentences6', '384sentences60', '384sentences61', '384sentences62', '384sentences63', '384sentences64', '384sentences65', '384sentences66', '384sentences67', '384sentences68', '384sentences69', '384sentences7', '384sentences70', '384sentences71', '384sentences72', '384sentences73', '384sentences74', '384sentences75', '384sentences76', '384sentences77', '384sentences78', '384sentences79', '384sentences8', '384sentences80', '384sentences81', '384sentences82', '384sentences83', '384sentences84', '384sentences85', '384sentences86', '384sentences87', '384sentences88', '384sentences89', '384sentences9', '384sentences90', '384sentences91', '384sentences92', '384sentences93', '384sentences94', '384sentences95', '384sentences96'])\n"
     ]
    }
   ],
   "source": [
    "print(glove_dic_senttocond.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old code\n",
    "#cols = df.corr(method='pearson').nlargest(k,target_col)[target_col].index\n",
    "#cm = df[cols].corr(method='pearson')\n",
    "#plt.figure(figsize=(15,8))\n",
    "#plt.tight_layout()\n",
    "#sns.heatmap(cm, annot=True, cmap = 'viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
