INFO:__main__:Running with args Namespace(log_level='DEBUG'), ['run', '--benchmark', 'Pereira2018-encoding-scrambled7', '--model', 'albert-xxlarge-v2']
DEBUG:result_caching._DiskStorage:Running function: neural_nlp.score/benchmark=Pereira2018-encoding-scrambled7,model=albert-xxlarge-v2,subsample=None
INFO:neural_nlp:Loading benchmark
INFO:neural_nlp:Running
DEBUG:neural_nlp.benchmarks.neural:I AM USING THIS DATA VERSION: Scr7
DEBUG:neural_nDEBUG:neural_nlp.benchmarks.s3._S3Storage:Loading from storage: neural_nlp.benchmarks.neural.PereiraEncodingScrambledLowPMI._load_assDEBUG:requests.packDEBUG:requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1)DEBUG:requests.packDEBUG:requests.packages.urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/albert-xxlarge-v2-config.json HTTP/1.1" 200 0
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v2-config.json from cache at /home/gretatu/.cache/torch/transformers/b3eed512e24335a76694282193217608ead013caa55330de3ff236d1f5695e6c.969ffb8d07aebbe39c189cbb0576be382e85f6960fcc4aec32eb97cd44be53a2
INFO:transformers.configuration_utils:Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 16384,
  "layer_norm_eps": 1e-12,
  "layers_to_keep": [],
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 64,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_memory_blocks": 0,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30000
}

DEBUG:requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1)DEBUG:requests.packDEBUG:requests.packages.urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/albert-xxlarge-v2-spiece.model HTTP/1.1" 200 0
INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v2-spiece.model from cache at /home/gretatu/.cache/torch/transformers/094b3b4d4ab5e624ae6ba8654d88cdb99b2d5a813b323295c37d58680a1c4127.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82cDEBUG:requests.packDEBUG:requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1)DEBUG:requests.packDEBUG:requests.packages.urllib3.connectionpool:https://s3.amazonaws.com:443 "HEAD /models.huggingface.co/bert/albert-xxlarge-v2-config.json HTTP/1.1" 200 0
INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v2-config.json from cache at /home/gretatu/.cache/torch/transformers/b3eed512e24335a76694282193217608ead013caa55330de3ff236d1f5695e6c.969ffb8d07aebbe39c189cbb0576be382e85f6960fcc4aec32eb97cd44be53a2
INFO:transformers.configuration_utils:Model config AlbertConfig {
  "architectures": [
    "AlbertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0,
  "bos_token_id": 2,
  "classifier_dropout_prob": 0.1,
  "down_scale_factor": 1,
  "embedding_size": 128,
  "eos_token_id": 3,
  "gap_size": 0,
  "hidden_act": "gelu_new",
  "hidden_dropout_prob": 0,
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "inner_group_num": 1,
  "intermediate_size": 16384,
  "layer_norm_eps": 1e-12,
  "layers_to_keep": [],
  "max_position_embeddings": 512,
  "model_type": "albert",
  "net_structure_type": 0,
  "num_attention_heads": 64,
  "num_hidden_groups": 1,
  "num_hidden_layers": 12,
  "num_memory_blocks": 0,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "type_vocab_size": 2,
  "vocab_size": 30000
}

DEBUG:requests.packages.urllib3.connectionpool:Starting new HTTPS connection (1): cdn.huggingface.co
DEBUG:requests.packages.urllib3.connectionpool:https://cdn.huggingface.co:443 "HEAD /albert-xxlarge-v2-pytorch_model.bin HTTP/1.1" 200 0
INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/albert-xxlarge-v2-pytorch_model.bin from cache at /home/gretatu/.cache/torch/transformers/99e96e90f18d97fce1d7b002130aa83f58cbf045d864ac5c1b9489387f9fe9d7.9ac42d6fae7d18840d74eaf2a6d817700ffdd5af9ae1a1DEBUG:result_cachinDEBUG:result_caching._XarrayStorage:Running function: neural_nlp.models.wrapper.core.ActivationsExtractorHelper._from_sentences_stored/identifier=albert-xxlarge-v2,stimuli_identifier=Pereira2018-lowPMI-243sentences1
INFO:neural_nlp.models.wrapper.core.ActivationsExtractorHelper:Running sentences
